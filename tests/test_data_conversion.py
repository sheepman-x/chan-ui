#!/usr/bin/env python3
"""
ç¼ è®ºæ•°æ®è½¬æ¢å•å…ƒæµ‹è¯•

è¯¥æµ‹è¯•æ–‡ä»¶éªŒè¯ä»chan.pyæ¡†æ¶è·å–çš„çœŸå®æ•°æ®ä¸å›¾è¡¨å±•ç¤ºæ‰€éœ€æ•°æ®æ ¼å¼çš„è½¬æ¢é€»è¾‘æ˜¯å¦æ­£ç¡®ã€‚
æµ‹è¯•è¦†ç›–ï¼š
1. Kçº¿æ•°æ®æå–å’Œè½¬æ¢
2. ç¬”æ•°æ®æå–å’Œåæ ‡æ˜ å°„
3. çº¿æ®µæ•°æ®æå–å’Œåæ ‡æ˜ å°„  
4. ä¸­æ¢æ•°æ®æå–å’Œåæ ‡æ˜ å°„
5. ä¹°å–ç‚¹æ•°æ®æå–å’Œåæ ‡æ˜ å°„
6. æ•°æ®å®Œæ•´æ€§å’Œä¸€è‡´æ€§éªŒè¯
"""

import unittest
import sys
import os
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)
chan_path = os.path.join(project_root, 'chan.py')
sys.path.append(chan_path)

try:
    from Chan import CChan
    from ChanConfig import CChanConfig
    from Common.CEnum import DATA_SRC, KL_TYPE, BI_DIR
    from chan_viz.data_service import StreamlitDataService
    CHAN_AVAILABLE = True
except ImportError as e:
    print(f"Warning: chan.py not available: {e}")
    CHAN_AVAILABLE = False

class TestChanDataConversion(unittest.TestCase):
    """ç¼ è®ºæ•°æ®è½¬æ¢æµ‹è¯•ç±»"""
    
    @classmethod
    def setUpClass(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ–"""
        if not CHAN_AVAILABLE:
            cls.skipTest(cls, "chan.py framework not available")
        
        cls.data_service = StreamlitDataService()
        
        # æµ‹è¯•è‚¡ç¥¨ä»£ç å’Œå‚æ•°
        cls.test_code = "sz.000001"  # å¹³å®‰é“¶è¡Œ
        cls.test_level = KL_TYPE.K_DAY
        cls.test_config = {
            "bi_strict": True,
            "zs_combine": True,
            "bs_type": "1,2,3a,3b"  # ä½¿ç”¨chan.pyæ”¯æŒçš„å‚æ•°
        }
        cls.start_date = "2023-01-01"
        cls.end_date = "2024-01-01"
        
        print(f"Setting up test with code: {cls.test_code}, level: {cls.test_level}")
    
    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„åˆå§‹åŒ–"""
        if not CHAN_AVAILABLE:
            self.skipTest("chan.py framework not available")
    
    def test_load_real_chan_data(self):
        """æµ‹è¯•åŠ è½½çœŸå®ç¼ è®ºæ•°æ®"""
        print("\n=== æµ‹è¯•åŠ è½½çœŸå®ç¼ è®ºæ•°æ® ===")
        
        try:
            # åˆ›å»ºCChanå¯¹è±¡è·å–çœŸå®æ•°æ®
            chan_config = CChanConfig(self.test_config)
            chan = CChan(
                code=self.test_code,
                begin_time=self.start_date,
                end_time=self.end_date,
                data_src=DATA_SRC.BAO_STOCK,
                lv_list=[self.test_level],
                config=chan_config
            )
            
            # è·å–Kçº¿æ•°æ®
            kline_list = chan.kl_datas[self.test_level]
            self.assertIsNotNone(kline_list, "Kçº¿æ•°æ®ä¸åº”ä¸ºç©º")
            self.assertGreater(len(kline_list), 0, "Kçº¿æ•°æ®åº”åŒ…å«è®°å½•")
            
            print(f"âœ“ æˆåŠŸåŠ è½½Kçº¿æ•°æ®ï¼Œå…± {len(kline_list)} ä¸ªåˆå¹¶Kçº¿")
            print(f"âœ“ ç¬”æ•°é‡: {len(kline_list.bi_list)}")
            print(f"âœ“ çº¿æ®µæ•°é‡: {len(kline_list.seg_list)}")
            print(f"âœ“ ä¸­æ¢æ•°é‡: {len(kline_list.zs_list)}")
            print(f"âœ“ ä¹°å–ç‚¹æ•°é‡: {len(kline_list.bs_point_lst.getSortedBspList())}")
            
            # å­˜å‚¨æµ‹è¯•æ•°æ®ä¾›å…¶ä»–æµ‹è¯•æ–¹æ³•ä½¿ç”¨
            self.__class__.chan_data = chan
            self.__class__.kline_list = kline_list
            
        except Exception as e:
            self.fail(f"åŠ è½½çœŸå®ç¼ è®ºæ•°æ®å¤±è´¥: {e}")
    
    def test_kline_data_conversion(self):
        """æµ‹è¯•Kçº¿æ•°æ®è½¬æ¢"""
        print("\n=== æµ‹è¯•Kçº¿æ•°æ®è½¬æ¢ ===")
        
        if not hasattr(self.__class__, 'kline_list'):
            self.skipTest("éœ€è¦å…ˆè¿è¡Œ test_load_real_chan_data")
        
        kline_list = self.__class__.kline_list
        converted_kline = self.data_service._extract_kline_data(kline_list)
        
        # éªŒè¯åŸºç¡€ç»“æ„
        required_keys = ['dates', 'open', 'close', 'low', 'high', 'volume']
        for key in required_keys:
            self.assertIn(key, converted_kline, f"Kçº¿æ•°æ®åº”åŒ…å« {key} å­—æ®µ")
        
        # éªŒè¯æ•°æ®é•¿åº¦ä¸€è‡´æ€§
        data_length = len(converted_kline['dates'])
        for key in required_keys:
            self.assertEqual(len(converted_kline[key]), data_length, 
                           f"æ‰€æœ‰Kçº¿å­—æ®µé•¿åº¦åº”ä¸€è‡´ï¼Œ{key}é•¿åº¦ä¸º{len(converted_kline[key])}")
        
        # éªŒè¯æ•°æ®ç±»å‹
        self.assertIsInstance(converted_kline['dates'][0], str, "æ—¥æœŸåº”ä¸ºå­—ç¬¦ä¸²ç±»å‹")
        self.assertIsInstance(converted_kline['open'][0], float, "å¼€ç›˜ä»·åº”ä¸ºæµ®ç‚¹æ•°")
        self.assertIsInstance(converted_kline['close'][0], float, "æ”¶ç›˜ä»·åº”ä¸ºæµ®ç‚¹æ•°")
        
        # éªŒè¯ä»·æ ¼åˆç†æ€§
        for i in range(data_length):
            self.assertGreaterEqual(converted_kline['high'][i], converted_kline['low'][i],
                                  f"ç¬¬{i}ä¸ªKçº¿æœ€é«˜ä»·åº”å¤§äºç­‰äºæœ€ä½ä»·")
            self.assertGreaterEqual(converted_kline['high'][i], converted_kline['open'][i],
                                  f"ç¬¬{i}ä¸ªKçº¿æœ€é«˜ä»·åº”å¤§äºç­‰äºå¼€ç›˜ä»·")
            self.assertGreaterEqual(converted_kline['high'][i], converted_kline['close'][i],
                                  f"ç¬¬{i}ä¸ªKçº¿æœ€é«˜ä»·åº”å¤§äºç­‰äºæ”¶ç›˜ä»·")
        
        print(f"âœ“ Kçº¿æ•°æ®è½¬æ¢æˆåŠŸï¼Œå…±{data_length}æ¡è®°å½•")
        print(f"âœ“ é¦–ä¸ªKçº¿: æ—¥æœŸ={converted_kline['dates'][0]}, å¼€ç›˜={converted_kline['open'][0]:.2f}")
        print(f"âœ“ æœ«ä¸ªKçº¿: æ—¥æœŸ={converted_kline['dates'][-1]}, æ”¶ç›˜={converted_kline['close'][-1]:.2f}")
    
    def test_bi_data_conversion(self):
        """æµ‹è¯•ç¬”æ•°æ®è½¬æ¢å’Œåæ ‡éªŒè¯"""
        print("\n=== æµ‹è¯•ç¬”æ•°æ®è½¬æ¢ ===")
        
        if not hasattr(self.__class__, 'kline_list'):
            self.skipTest("éœ€è¦å…ˆè¿è¡Œ test_load_real_chan_data")
        
        kline_list = self.__class__.kline_list
        bi_list = kline_list.bi_list
        
        if len(bi_list) == 0:
            self.skipTest("å½“å‰æ•°æ®æ²¡æœ‰ç¬”ï¼Œè·³è¿‡ç¬”æ•°æ®è½¬æ¢æµ‹è¯•")
        
        converted_bi = self.data_service._extract_bi_data(bi_list, self.data_service._build_klu_index_mapping(kline_list))
        
        # éªŒè¯åŸºç¡€ç»“æ„
        self.assertIsInstance(converted_bi, list, "ç¬”æ•°æ®åº”ä¸ºåˆ—è¡¨")
        self.assertGreater(len(converted_bi), 0, "åº”åŒ…å«ç¬”æ•°æ®")
        
        total_klu_count = sum(len(klc.lst) for klc in kline_list)
        print(f"âœ“ Kçº¿å•å…ƒæ€»æ•°: {total_klu_count}")
        
        for i, bi in enumerate(converted_bi):
            required_keys = ['x', 'y', 'type', 'direction']
            for key in required_keys:
                self.assertIn(key, bi, f"ç¬¬{i}ä¸ªç¬”åº”åŒ…å« {key} å­—æ®µ")
            
            # éªŒè¯åæ ‡æ•°æ®
            self.assertIsInstance(bi['x'], list, "ç¬”çš„xåæ ‡åº”ä¸ºåˆ—è¡¨")
            self.assertIsInstance(bi['y'], list, "ç¬”çš„yåæ ‡åº”ä¸ºåˆ—è¡¨") 
            self.assertEqual(len(bi['x']), 2, "ç¬”åº”æœ‰èµ·ç‚¹å’Œç»ˆç‚¹xåæ ‡")
            self.assertEqual(len(bi['y']), 2, "ç¬”åº”æœ‰èµ·ç‚¹å’Œç»ˆç‚¹yåæ ‡")
            
            # éªŒè¯ç´¢å¼•èŒƒå›´
            start_idx, end_idx = bi['x']
            self.assertGreaterEqual(start_idx, 0, f"ç¬¬{i}ä¸ªç¬”èµ·å§‹ç´¢å¼•åº”â‰¥0")
            self.assertLess(end_idx, total_klu_count, f"ç¬¬{i}ä¸ªç¬”ç»“æŸç´¢å¼•åº”å°äºæ€»Kçº¿æ•°")
            self.assertLess(start_idx, end_idx, f"ç¬¬{i}ä¸ªç¬”èµ·å§‹ç´¢å¼•åº”å°äºç»“æŸç´¢å¼•")
            
            # éªŒè¯ä»·æ ¼æ•°æ®
            start_price, end_price = bi['y']
            self.assertIsInstance(start_price, float, "ç¬”èµ·å§‹ä»·æ ¼åº”ä¸ºæµ®ç‚¹æ•°")
            self.assertIsInstance(end_price, float, "ç¬”ç»“æŸä»·æ ¼åº”ä¸ºæµ®ç‚¹æ•°")
            self.assertGreater(start_price, 0, "ç¬”èµ·å§‹ä»·æ ¼åº”å¤§äº0")
            self.assertGreater(end_price, 0, "ç¬”ç»“æŸä»·æ ¼åº”å¤§äº0")
            
            # éªŒè¯æ–¹å‘é€»è¾‘
            direction = bi['direction']
            self.assertIn(direction, ['up', 'down'], f"ç¬¬{i}ä¸ªç¬”æ–¹å‘åº”ä¸ºupæˆ–down")
            
            if direction == 'up':
                self.assertLess(start_price, end_price, f"ä¸Šå‡ç¬”ç¬¬{i}ä¸ªèµ·å§‹ä»·æ ¼åº”å°äºç»“æŸä»·æ ¼")
            else:  # down
                self.assertGreater(start_price, end_price, f"ä¸‹é™ç¬”ç¬¬{i}ä¸ªèµ·å§‹ä»·æ ¼åº”å¤§äºç»“æŸä»·æ ¼")
        
        print(f"âœ“ ç¬”æ•°æ®è½¬æ¢æˆåŠŸï¼Œå…±{len(converted_bi)}ä¸ªç¬”")
        for i, bi in enumerate(converted_bi[:3]):  # æ˜¾ç¤ºå‰3ä¸ªç¬”çš„ä¿¡æ¯
            print(f"  ç¬”{i+1}: ç´¢å¼•{bi['x'][0]}->{bi['x'][1]}, "
                  f"ä»·æ ¼{bi['y'][0]:.2f}->{bi['y'][1]:.2f}, æ–¹å‘{bi['direction']}")
    
    def test_segment_data_conversion(self):
        """æµ‹è¯•çº¿æ®µæ•°æ®è½¬æ¢"""
        print("\n=== æµ‹è¯•çº¿æ®µæ•°æ®è½¬æ¢ ===")
        
        if not hasattr(self.__class__, 'kline_list'):
            self.skipTest("éœ€è¦å…ˆè¿è¡Œ test_load_real_chan_data")
        
        kline_list = self.__class__.kline_list
        seg_list = kline_list.seg_list
        
        if len(seg_list) == 0:
            self.skipTest("å½“å‰æ•°æ®æ²¡æœ‰çº¿æ®µï¼Œè·³è¿‡çº¿æ®µæ•°æ®è½¬æ¢æµ‹è¯•")
        
        converted_seg = self.data_service._extract_segment_data(seg_list, self.data_service._build_klu_index_mapping(kline_list))
        
        total_klu_count = sum(len(klc.lst) for klc in kline_list)
        
        for i, seg in enumerate(converted_seg):
            required_keys = ['x', 'y', 'type']
            for key in required_keys:
                self.assertIn(key, seg, f"ç¬¬{i}ä¸ªçº¿æ®µåº”åŒ…å« {key} å­—æ®µ")
            
            # éªŒè¯åæ ‡æ•°æ®
            self.assertEqual(len(seg['x']), 2, "çº¿æ®µåº”æœ‰èµ·ç‚¹å’Œç»ˆç‚¹xåæ ‡")
            self.assertEqual(len(seg['y']), 2, "çº¿æ®µåº”æœ‰èµ·ç‚¹å’Œç»ˆç‚¹yåæ ‡")
            
            # éªŒè¯ç´¢å¼•èŒƒå›´
            start_idx, end_idx = seg['x']
            self.assertGreaterEqual(start_idx, 0, f"ç¬¬{i}ä¸ªçº¿æ®µèµ·å§‹ç´¢å¼•åº”â‰¥0")
            self.assertLess(end_idx, total_klu_count, f"ç¬¬{i}ä¸ªçº¿æ®µç»“æŸç´¢å¼•åº”å°äºæ€»Kçº¿æ•°")
            self.assertLess(start_idx, end_idx, f"ç¬¬{i}ä¸ªçº¿æ®µèµ·å§‹ç´¢å¼•åº”å°äºç»“æŸç´¢å¼•")
            
            # éªŒè¯ä»·æ ¼æ•°æ®  
            start_price, end_price = seg['y']
            self.assertGreater(start_price, 0, "çº¿æ®µèµ·å§‹ä»·æ ¼åº”å¤§äº0")
            self.assertGreater(end_price, 0, "çº¿æ®µç»“æŸä»·æ ¼åº”å¤§äº0")
        
        print(f"âœ“ çº¿æ®µæ•°æ®è½¬æ¢æˆåŠŸï¼Œå…±{len(converted_seg)}ä¸ªçº¿æ®µ")
        for i, seg in enumerate(converted_seg[:3]):  # æ˜¾ç¤ºå‰3ä¸ªçº¿æ®µçš„ä¿¡æ¯
            print(f"  çº¿æ®µ{i+1}: ç´¢å¼•{seg['x'][0]}->{seg['x'][1]}, "
                  f"ä»·æ ¼{seg['y'][0]:.2f}->{seg['y'][1]:.2f}")
    
    def test_zs_data_conversion(self):
        """æµ‹è¯•ä¸­æ¢æ•°æ®è½¬æ¢"""
        print("\n=== æµ‹è¯•ä¸­æ¢æ•°æ®è½¬æ¢ ===")
        
        if not hasattr(self.__class__, 'kline_list'):
            self.skipTest("éœ€è¦å…ˆè¿è¡Œ test_load_real_chan_data")
        
        kline_list = self.__class__.kline_list
        zs_list = kline_list.zs_list
        
        if len(zs_list) == 0:
            self.skipTest("å½“å‰æ•°æ®æ²¡æœ‰ä¸­æ¢ï¼Œè·³è¿‡ä¸­æ¢æ•°æ®è½¬æ¢æµ‹è¯•")
        
        converted_zs = self.data_service._extract_zs_data(zs_list, self.data_service._build_klu_index_mapping(kline_list))
        
        total_klu_count = sum(len(klc.lst) for klc in kline_list)
        
        for i, zs in enumerate(converted_zs):
            required_keys = ['x', 'y', 'type']
            for key in required_keys:
                self.assertIn(key, zs, f"ç¬¬{i}ä¸ªä¸­æ¢åº”åŒ…å« {key} å­—æ®µ")
            
            # éªŒè¯åæ ‡æ•°æ®
            self.assertEqual(len(zs['x']), 2, "ä¸­æ¢åº”æœ‰èµ·ç‚¹å’Œç»ˆç‚¹xåæ ‡")
            self.assertEqual(len(zs['y']), 2, "ä¸­æ¢åº”æœ‰ä½ç‚¹å’Œé«˜ç‚¹yåæ ‡")
            
            # éªŒè¯ç´¢å¼•èŒƒå›´
            start_idx, end_idx = zs['x']
            self.assertGreaterEqual(start_idx, 0, f"ç¬¬{i}ä¸ªä¸­æ¢èµ·å§‹ç´¢å¼•åº”â‰¥0")
            self.assertLess(end_idx, total_klu_count, f"ç¬¬{i}ä¸ªä¸­æ¢ç»“æŸç´¢å¼•åº”å°äºæ€»Kçº¿æ•°")
            self.assertLessEqual(start_idx, end_idx, f"ç¬¬{i}ä¸ªä¸­æ¢èµ·å§‹ç´¢å¼•åº”å°äºç­‰äºç»“æŸç´¢å¼•")
            
            # éªŒè¯ä»·æ ¼èŒƒå›´  
            low_price, high_price = zs['y']
            self.assertGreater(low_price, 0, "ä¸­æ¢ä½ç‚¹ä»·æ ¼åº”å¤§äº0")
            self.assertGreater(high_price, 0, "ä¸­æ¢é«˜ç‚¹ä»·æ ¼åº”å¤§äº0")
            self.assertLessEqual(low_price, high_price, f"ç¬¬{i}ä¸ªä¸­æ¢ä½ç‚¹åº”å°äºç­‰äºé«˜ç‚¹")
        
        print(f"âœ“ ä¸­æ¢æ•°æ®è½¬æ¢æˆåŠŸï¼Œå…±{len(converted_zs)}ä¸ªä¸­æ¢")
        for i, zs in enumerate(converted_zs[:3]):  # æ˜¾ç¤ºå‰3ä¸ªä¸­æ¢çš„ä¿¡æ¯
            print(f"  ä¸­æ¢{i+1}: ç´¢å¼•{zs['x'][0]}->{zs['x'][1]}, "
                  f"ä»·æ ¼èŒƒå›´{zs['y'][0]:.2f}-{zs['y'][1]:.2f}")
    
    def test_bsp_data_conversion(self):
        """æµ‹è¯•ä¹°å–ç‚¹æ•°æ®è½¬æ¢"""
        print("\n=== æµ‹è¯•ä¹°å–ç‚¹æ•°æ®è½¬æ¢ ===")
        
        if not hasattr(self.__class__, 'kline_list'):
            self.skipTest("éœ€è¦å…ˆè¿è¡Œ test_load_real_chan_data")
        
        kline_list = self.__class__.kline_list
        bsp_list = kline_list.bs_point_lst
        
        if len(bsp_list.getSortedBspList()) == 0:
            self.skipTest("å½“å‰æ•°æ®æ²¡æœ‰ä¹°å–ç‚¹ï¼Œè·³è¿‡ä¹°å–ç‚¹æ•°æ®è½¬æ¢æµ‹è¯•")
        
        converted_bsp = self.data_service._extract_bsp_data(bsp_list)
        
        total_klu_count = sum(len(klc.lst) for klc in kline_list)
        
        for i, bsp in enumerate(converted_bsp):
            required_keys = ['kl_idx', 'price', 'is_buy', 'type']
            for key in required_keys:
                self.assertIn(key, bsp, f"ç¬¬{i}ä¸ªä¹°å–ç‚¹åº”åŒ…å« {key} å­—æ®µ")
            
            # éªŒè¯ç´¢å¼•èŒƒå›´
            kl_idx = bsp['kl_idx']
            self.assertGreaterEqual(kl_idx, 0, f"ç¬¬{i}ä¸ªä¹°å–ç‚¹Kçº¿ç´¢å¼•åº”â‰¥0")
            self.assertLess(kl_idx, total_klu_count, f"ç¬¬{i}ä¸ªä¹°å–ç‚¹Kçº¿ç´¢å¼•åº”å°äºæ€»Kçº¿æ•°")
            
            # éªŒè¯ä»·æ ¼
            price = bsp['price']
            self.assertIsInstance(price, float, "ä¹°å–ç‚¹ä»·æ ¼åº”ä¸ºæµ®ç‚¹æ•°")
            self.assertGreater(price, 0, "ä¹°å–ç‚¹ä»·æ ¼åº”å¤§äº0")
            
            # éªŒè¯ä¹°å–å±æ€§
            is_buy = bsp['is_buy']
            self.assertIsInstance(is_buy, bool, "is_buyåº”ä¸ºå¸ƒå°”å€¼")
            
            # éªŒè¯ç±»å‹
            bsp_type = bsp['type']
            self.assertIsInstance(bsp_type, str, "ä¹°å–ç‚¹ç±»å‹åº”ä¸ºå­—ç¬¦ä¸²")
        
        buy_count = sum(1 for bsp in converted_bsp if bsp['is_buy'])
        sell_count = len(converted_bsp) - buy_count
        
        print(f"âœ“ ä¹°å–ç‚¹æ•°æ®è½¬æ¢æˆåŠŸï¼Œå…±{len(converted_bsp)}ä¸ªä¹°å–ç‚¹")
        print(f"  å…¶ä¸­ä¹°ç‚¹{buy_count}ä¸ªï¼Œå–ç‚¹{sell_count}ä¸ª")
        
        for i, bsp in enumerate(converted_bsp[:3]):  # æ˜¾ç¤ºå‰3ä¸ªä¹°å–ç‚¹çš„ä¿¡æ¯
            label = "ä¹°ç‚¹" if bsp['is_buy'] else "å–ç‚¹"
            print(f"  {label}{i+1}: Kçº¿ç´¢å¼•{bsp['kl_idx']}, ä»·æ ¼{bsp['price']:.2f}, ç±»å‹{bsp['type']}")
    
    def test_complete_data_conversion_integration(self):
        """æµ‹è¯•å®Œæ•´æ•°æ®è½¬æ¢é›†æˆ"""
        print("\n=== æµ‹è¯•å®Œæ•´æ•°æ®è½¬æ¢é›†æˆ ===")
        
        try:
            # ä½¿ç”¨data_serviceçš„å®Œæ•´è½¬æ¢æµç¨‹
            converted_data = self.data_service.load_chan_data(
                code=self.test_code,
                level="K_DAY",  # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼
                config=self.test_config,
                start_date=self.start_date,
                end_date=self.end_date
            )
            
            # éªŒè¯é¡¶çº§ç»“æ„
            required_top_keys = ['kline', 'bi', 'segment', 'central_zone', 'buy_sell_points']
            for key in required_top_keys:
                self.assertIn(key, converted_data, f"è½¬æ¢åçš„æ•°æ®åº”åŒ…å« {key}")
            
            # éªŒè¯Kçº¿æ•°æ®ç»“æ„
            kline_data = converted_data['kline']
            required_kline_keys = ['dates', 'open', 'close', 'low', 'high', 'volume']
            for key in required_kline_keys:
                self.assertIn(key, kline_data, f"Kçº¿æ•°æ®åº”åŒ…å« {key}")
            
            # éªŒè¯æ•°æ®ä¸€è‡´æ€§ï¼šæ‰€æœ‰æ—¶é—´ç›¸å…³çš„ç´¢å¼•éƒ½åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            dates_count = len(kline_data['dates'])
            
            # éªŒè¯ç¬”çš„ç´¢å¼•èŒƒå›´
            for bi in converted_data['bi']:
                for idx in bi['x']:
                    self.assertGreaterEqual(idx, 0, "ç¬”ç´¢å¼•åº”â‰¥0")
                    self.assertLess(idx, dates_count, "ç¬”ç´¢å¼•åº”å°äºæ—¥æœŸæ€»æ•°")
            
            # éªŒè¯çº¿æ®µçš„ç´¢å¼•èŒƒå›´
            for seg in converted_data['segment']:
                for idx in seg['x']:
                    self.assertGreaterEqual(idx, 0, "çº¿æ®µç´¢å¼•åº”â‰¥0")
                    self.assertLess(idx, dates_count, "çº¿æ®µç´¢å¼•åº”å°äºæ—¥æœŸæ€»æ•°")
            
            # éªŒè¯ä¸­æ¢çš„ç´¢å¼•èŒƒå›´
            for zs in converted_data['central_zone']:
                for idx in zs['x']:
                    self.assertGreaterEqual(idx, 0, "ä¸­æ¢ç´¢å¼•åº”â‰¥0")
                    self.assertLess(idx, dates_count, "ä¸­æ¢ç´¢å¼•åº”å°äºæ—¥æœŸæ€»æ•°")
            
            # éªŒè¯ä¹°å–ç‚¹çš„ç´¢å¼•èŒƒå›´
            for bsp in converted_data['buy_sell_points']:
                self.assertGreaterEqual(bsp['kl_idx'], 0, "ä¹°å–ç‚¹ç´¢å¼•åº”â‰¥0")
                self.assertLess(bsp['kl_idx'], dates_count, "ä¹°å–ç‚¹ç´¢å¼•åº”å°äºæ—¥æœŸæ€»æ•°")
            
            print("âœ“ å®Œæ•´æ•°æ®è½¬æ¢é›†æˆæµ‹è¯•é€šè¿‡")
            print(f"  Kçº¿æ•°æ®: {len(kline_data['dates'])} æ¡")
            print(f"  ç¬”æ•°æ®: {len(converted_data['bi'])} ä¸ª")  
            print(f"  çº¿æ®µæ•°æ®: {len(converted_data['segment'])} ä¸ª")
            print(f"  ä¸­æ¢æ•°æ®: {len(converted_data['central_zone'])} ä¸ª")
            print(f"  ä¹°å–ç‚¹æ•°æ®: {len(converted_data['buy_sell_points'])} ä¸ª")
            
            # è¿›è¡Œæ•°æ®é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥
            self._validate_data_logic_consistency(converted_data)
            
        except Exception as e:
            self.fail(f"å®Œæ•´æ•°æ®è½¬æ¢é›†æˆæµ‹è¯•å¤±è´¥: {e}")
    
    def _validate_data_logic_consistency(self, data: Dict[str, Any]):
        """éªŒè¯æ•°æ®é€»è¾‘ä¸€è‡´æ€§"""
        print("\n--- æ•°æ®é€»è¾‘ä¸€è‡´æ€§éªŒè¯ ---")
        
        # éªŒè¯ç¬”çš„è¿ç»­æ€§ï¼šç›¸é‚»ç¬”çš„ç»ˆç‚¹å’Œèµ·ç‚¹åº”è¯¥è¿æ¥
        bi_data = data['bi']
        if len(bi_data) > 1:
            for i in range(len(bi_data) - 1):
                current_end_idx = bi_data[i]['x'][1]
                next_start_idx = bi_data[i + 1]['x'][0] 
                # æ³¨æ„ï¼šç¬”ä¹‹é—´å¯èƒ½ä¸æ˜¯å®Œå…¨è¿ç»­çš„ï¼Œå› ä¸ºå¯èƒ½æœ‰åˆå¹¶Kçº¿
                self.assertLessEqual(current_end_idx, next_start_idx, 
                                   f"ç¬”{i+1}çš„ç»ˆç‚¹ç´¢å¼•åº”â‰¤ç¬”{i+2}çš„èµ·ç‚¹ç´¢å¼•")
        
        # éªŒè¯æ–¹å‘äº¤æ›¿ï¼šç›¸é‚»ç¬”çš„æ–¹å‘åº”è¯¥ç›¸å
        if len(bi_data) > 1:
            for i in range(len(bi_data) - 1):
                current_direction = bi_data[i]['direction']
                next_direction = bi_data[i + 1]['direction']
                self.assertNotEqual(current_direction, next_direction,
                                  f"ç›¸é‚»ç¬”{i+1}å’Œ{i+2}çš„æ–¹å‘åº”è¯¥ç›¸å")
        
        # éªŒè¯ä¹°å–ç‚¹ä½ç½®åˆç†æ€§ï¼šä¹°å–ç‚¹åº”è¯¥åœ¨Kçº¿ç´¢å¼•èŒƒå›´å†…
        dates_count = len(data['kline']['dates'])
        for bsp in data['buy_sell_points']:
            kl_idx = bsp['kl_idx']
            self.assertGreaterEqual(kl_idx, 0, "ä¹°å–ç‚¹ç´¢å¼•åº”â‰¥0")
            self.assertLess(kl_idx, dates_count, "ä¹°å–ç‚¹ç´¢å¼•åº”åœ¨Kçº¿èŒƒå›´å†…")
        
        print("âœ“ æ•°æ®é€»è¾‘ä¸€è‡´æ€§éªŒè¯é€šè¿‡")


def run_tests():
    """è¿è¡Œæµ‹è¯•çš„ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª ç¼ è®ºæ•°æ®è½¬æ¢å•å…ƒæµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶ï¼ŒæŒ‰ç…§ä¾èµ–é¡ºåºæ‰§è¡Œ
    test_suite = unittest.TestSuite()
    test_class = TestChanDataConversion
    
    # é¦–å…ˆæ‰§è¡Œæ•°æ®åŠ è½½æµ‹è¯•
    test_suite.addTest(test_class('test_load_real_chan_data'))
    
    # ç„¶åæ‰§è¡Œå„ä¸ªç»„ä»¶çš„æµ‹è¯•
    test_suite.addTest(test_class('test_kline_data_conversion'))
    test_suite.addTest(test_class('test_bi_data_conversion'))
    test_suite.addTest(test_class('test_segment_data_conversion'))
    test_suite.addTest(test_class('test_zs_data_conversion'))
    test_suite.addTest(test_class('test_bsp_data_conversion'))
    
    # æœ€åæ‰§è¡Œé›†æˆæµ‹è¯•
    test_suite.addTest(test_class('test_complete_data_conversion_integration'))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
    result = runner.run(test_suite)
    
    print("\n" + "=" * 60)
    print("ğŸ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"è¿è¡Œæµ‹è¯•æ•°: {result.testsRun}")
    print(f"å¤±è´¥æ•°: {len(result.failures)}")
    print(f"é”™è¯¯æ•°: {len(result.errors)}")
    print(f"è·³è¿‡æ•°: {len(result.skipped)}")
    
    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    if result.skipped:
        print("\nâ­ï¸ è·³è¿‡çš„æµ‹è¯•:")
        for test, reason in result.skipped:
            print(f"  - {test}: {reason}")
    
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100 if result.testsRun > 0 else 0
    print(f"\nâœ… æˆåŠŸç‡: {success_rate:.1f}%")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)